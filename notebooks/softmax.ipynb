{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import triton\n",
    "import triton.language as tl\n",
    "\n",
    "@triton.jit\n",
    "def online_softmax_kernel(\n",
    "    q_ptr, k_ptr, v_ptr, out_ptr,\n",
    "    n_heads, d_head, kv_seq_len,\n",
    "    scale, predicted_max,\n",
    "    BLOCK_D: tl.constexpr\n",
    "):\n",
    "    # offset 계산\n",
    "    head_id = tl.program_id(0)\n",
    "    off_q = head_id * d_head\n",
    "    off_k = head_id * kv_seq_len * d_head\n",
    "    off_v = head_id * kv_seq_len * d_head\n",
    "\n",
    "    q = tl.load(q_ptr + off_q + tl.arange(0, d_head))      # [d_head]\n",
    "    sum_exp = 0.0\n",
    "    output = tl.zeros([d_head], dtype=tl.float32)\n",
    "\n",
    "    for i in range(0, kv_seq_len):\n",
    "        k = tl.load(k_ptr + off_k + i * d_head + tl.arange(0, d_head))\n",
    "        v = tl.load(v_ptr + off_v + i * d_head + tl.arange(0, d_head))\n",
    "\n",
    "        logit = tl.sum(q * k, axis=0) * scale\n",
    "        shifted_logit = logit - predicted_max\n",
    "        exp_val = tl.exp(shifted_logit)\n",
    "        sum_exp += exp_val\n",
    "\n",
    "        output += exp_val * v\n",
    "\n",
    "    output /= sum_exp\n",
    "    tl.store(out_ptr + off_q + tl.arange(0, d_head), output)\n"
   ],
   "id": "540335e69eb613c6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def triton_decode_softmax(q, k, v, scale, predicted_max):\n",
    "    B, H, _, D = q.shape  # q: [B, H, 1, D]\n",
    "    kv_seq_len = k.shape[2]\n",
    "\n",
    "    output = torch.empty_like(q)\n",
    "\n",
    "    # Flatten inputs\n",
    "    q_ptr = q.contiguous().view(-1)\n",
    "    k_ptr = k.contiguous().view(-1)\n",
    "    v_ptr = v.contiguous().view(-1)\n",
    "    out_ptr = output.contiguous().view(-1)\n",
    "\n",
    "    grid = lambda meta: (H,)\n",
    "\n",
    "    online_softmax_kernel[grid](\n",
    "        q_ptr, k_ptr, v_ptr, out_ptr,\n",
    "        H, D, kv_seq_len,\n",
    "        scale, predicted_max,\n",
    "        BLOCK_D=D\n",
    "    )\n",
    "\n",
    "    return output\n"
   ],
   "id": "bfcc8bd1b975efcb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# PyTorch reference\n",
    "attn_scores = (q @ k.transpose(-2, -1)) * scale\n",
    "attn = F.softmax(attn_scores, dim=-1)\n",
    "out_ref = attn @ v  # shape: [B, H, 1, D]\n",
    "\n",
    "# Triton version\n",
    "out_triton = triton_decode_softmax(q, k, v, scale, predicted_max)\n",
    "\n",
    "# Check accuracy\n",
    "max_diff = (out_ref - out_triton).abs().max()\n",
    "print(\"Max diff:\", max_diff.item())\n"
   ],
   "id": "28c4ca3da5ec90e7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "70c07b8cdb70e797"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
