{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Importing libraries",
   "id": "eba822f51503a573"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-30T10:41:14.605307Z",
     "start_time": "2025-05-30T10:41:07.534521Z"
    }
   },
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from typing import Tuple\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import wandb\n",
    "from src.utils import set_seed, load_text, split_text\n",
    "from src.config import ModelConfig, TrainConfig, GenerationConfig\n",
    "from src.tokenizer import CharTokenizer\n",
    "from models.GPT2 import GPT\n",
    "from src.train import Trainer"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Configuration",
   "id": "6d9c4037c51cdb88"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T10:41:14.794922Z",
     "start_time": "2025-05-30T10:41:14.791663Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_config = ModelConfig(\n",
    "    max_seq_len=256,\n",
    "    d_embed=128,\n",
    "    n_layers=4,\n",
    "    n_heads=4,\n",
    "    d_head=32,\n",
    "    d_ff=512,\n",
    "    router_free=True,\n",
    "    n_experts=4,\n",
    "    n_activated_experts=1\n",
    ")\n",
    "\n",
    "train_config = TrainConfig(\n",
    "    debug=False,\n",
    "    wandb_project=\"nanoGPT\",\n",
    "    per_device_train_batch_size=256,\n",
    "    per_device_eval_batch_size=512,\n",
    "    gradient_accumulation_steps=512 // 256,\n",
    "    num_train_epochs=1,\n",
    "    learning_rate=2e-3,\n",
    "    eval_steps=100,\n",
    "    mixed_precision=False,\n",
    "    matmul_precision=\"high\",\n",
    ")\n",
    "\n",
    "generation_config = GenerationConfig(\n",
    "    max_new_tokens=1000\n",
    ")"
   ],
   "id": "6ab70e4c2df8b424",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Weights & Biases",
   "id": "5ed87542e4fab7cf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T10:41:15.601713Z",
     "start_time": "2025-05-30T10:41:14.809649Z"
    }
   },
   "cell_type": "code",
   "source": [
    "load_dotenv()\n",
    "wandb.login(key=os.environ.get(\"WANDB_API_KEY\"))"
   ],
   "id": "604dc457c3aca161",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mpathfinderkr\u001B[0m to \u001B[32mhttps://api.wandb.ai\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Utils",
   "id": "d2c2b27f0a363231"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Reproducibility",
   "id": "37c47b3c933f39c8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T10:41:15.663340Z",
     "start_time": "2025-05-30T10:41:15.657708Z"
    }
   },
   "cell_type": "code",
   "source": "set_seed(train_config.seed)",
   "id": "43f42a50ba95e818",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set to 42\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Device",
   "id": "dab21e872039a939"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T10:41:15.723029Z",
     "start_time": "2025-05-30T10:41:15.720292Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\")\n",
    "torch.set_float32_matmul_precision(train_config.matmul_precision)  # Tensor Cores"
   ],
   "id": "baef08c6ac2c7d4f",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Dataset",
   "id": "1c5701db44321787"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T10:41:15.786404Z",
     "start_time": "2025-05-30T10:41:15.781473Z"
    }
   },
   "cell_type": "code",
   "source": "shakespeare_text = load_text(\"../datasets/Shakespeare/shakespeare.txt\")",
   "id": "d733f8aed190ecca",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded text data from ../datasets/Shakespeare/shakespeare.txt (length: 1115394 characters).\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T10:41:15.844393Z",
     "start_time": "2025-05-30T10:41:15.841578Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if train_config.debug:\n",
    "    print(shakespeare_text[:1000])"
   ],
   "id": "9d577742c3f4cd56",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Tokenizer",
   "id": "395612ec5147789b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T10:41:15.916893Z",
     "start_time": "2025-05-30T10:41:15.904579Z"
    }
   },
   "cell_type": "code",
   "source": [
    "char_tokenizer = CharTokenizer()\n",
    "char_tokenizer.build_vocab(text=shakespeare_text)\n",
    "model_config.vocab_size = char_tokenizer.vocab_size"
   ],
   "id": "82f100c72b1ff4e7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique characters: 65\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T10:41:15.968895Z",
     "start_time": "2025-05-30T10:41:15.966274Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if train_config.debug:\n",
    "    print(f\"Vocabulary size: {char_tokenizer.vocab_size}\")\n",
    "    print(\"Vocabulary:\", char_tokenizer.char2idx)"
   ],
   "id": "33ca255715696a09",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Preprocessing",
   "id": "56e97a156915cf36"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T10:41:16.027235Z",
     "start_time": "2025-05-30T10:41:16.024192Z"
    }
   },
   "cell_type": "code",
   "source": "train_text, val_text = split_text(shakespeare_text, val_size=0.1)",
   "id": "b4bce7cbc68e8431",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T10:41:16.276707Z",
     "start_time": "2025-05-30T10:41:16.081648Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, text: str, tokenizer: CharTokenizer, max_seq_len: int):\n",
    "        self.encoded = tokenizer.encode(text)\n",
    "        self.max_seq_len = max_seq_len\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.encoded) - self.max_seq_len\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        input_ids = self.encoded[idx:idx + self.max_seq_len]\n",
    "        target_ids = self.encoded[idx + 1:idx + self.max_seq_len + 1]\n",
    "        return input_ids, target_ids\n",
    "\n",
    "def collate_fn(batch):\n",
    "    input_ids = torch.stack([item[0] for item in batch])\n",
    "    target_ids = torch.stack([item[1] for item in batch])\n",
    "    return {\"input_ids\": input_ids, \"target_ids\": target_ids}\n",
    "\n",
    "train_dataset = TextDataset(train_text, char_tokenizer, model_config.max_seq_len)\n",
    "val_dataset = TextDataset(val_text, char_tokenizer, model_config.max_seq_len)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    collate_fn=collate_fn,\n",
    "    batch_size=train_config.per_device_eval_batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    collate_fn=collate_fn,\n",
    "    batch_size=train_config.per_device_eval_batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=4\n",
    ")"
   ],
   "id": "9365bcc860bc94c0",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T10:41:16.295801Z",
     "start_time": "2025-05-30T10:41:16.290559Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if train_config.debug:\n",
    "    sample_batch = next(iter(train_loader))\n",
    "    print(f\"Sample input IDs: {sample_batch['input_ids'][:5]}\")\n",
    "    print(f\"Sample target IDs: {sample_batch['target_ids'][:5]}\")"
   ],
   "id": "48cad8c822157759",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model",
   "id": "ab879cf42408dc15"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T10:41:17.912389Z",
     "start_time": "2025-05-30T10:41:16.313851Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize the model\n",
    "model = GPT(model_config).to(device)\n",
    "model = torch.compile(model)\n",
    "print(model)\n",
    "print(f\"Number of parameters: {model.num_params() / 1e6:.2f}M\")\n",
    "print(f\"Number of active parameters: {model.num_active_params() / 1e6:.2f}M\")"
   ],
   "id": "afd4c978bd93f6c2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OptimizedModule(\n",
      "  (_orig_mod): GPT(\n",
      "    (embedding): Embedding(65, 128)\n",
      "    (positional_encoding): Embedding(256, 128)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (blocks): ModuleList(\n",
      "      (0-3): 4 x Block(\n",
      "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): MultiHeadAttention(\n",
      "          (qkv_proj): Linear(in_features=128, out_features=384, bias=True)\n",
      "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): RouterFreeMoE(\n",
      "          (experts): ModuleList(\n",
      "            (0-3): 4 x Expert(\n",
      "              (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
      "              (activation): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "    (lm_head): Linear(in_features=128, out_features=65, bias=False)\n",
      "  )\n",
      ")\n",
      "Number of parameters: 2.41M\n",
      "Number of active parameters: 0.83M\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Speedometer",
   "id": "a23d13fbb910e997"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "fbab8f36f063efa5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Training",
   "id": "1d1d9a614384a0e1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T10:48:32.601941Z",
     "start_time": "2025-05-30T10:41:18.007924Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainer = Trainer(\n",
    "        train_config=train_config,\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        device=device\n",
    ")\n",
    "trainer.train()"
   ],
   "id": "6ebc75004c7fa8c4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/workspace/PathFinder/notebooks/wandb/run-20250530_104118-sfkj2vsd</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/pathfinderkr/nanoGPT/runs/sfkj2vsd' target=\"_blank\">nanoGPT-MoE-2025-05-30_10-41-13</a></strong> to <a href='https://wandb.ai/pathfinderkr/nanoGPT' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/pathfinderkr/nanoGPT' target=\"_blank\">https://wandb.ai/pathfinderkr/nanoGPT</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/pathfinderkr/nanoGPT/runs/sfkj2vsd' target=\"_blank\">https://wandb.ai/pathfinderkr/nanoGPT/runs/sfkj2vsd</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 980/980 [07:11<00:00,  2.27it/s, grad_norm=0.0893, loss=1.4213, lr=0.000000]  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>Grad Norm</td><td>â–„â–„â–â–â–‚â–‚â–ˆâ–‚â–‚â–‚â–„â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–â–â–â–â–â–â–â–</td></tr><tr><td>Learning Rate</td><td>â–‚â–ƒâ–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–†â–†â–†â–…â–…â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–</td></tr><tr><td>Train Loss</td><td>â–ˆâ–ˆâ–‡â–†â–…â–…â–…â–…â–…â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>Val Loss</td><td>â–ˆâ–†â–ƒâ–‚â–‚â–â–â–â–â–</td></tr><tr><td>Val Perplexity</td><td>â–ˆâ–…â–ƒâ–‚â–â–â–â–â–â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>1</td></tr><tr><td>Grad Norm</td><td>0.0893</td></tr><tr><td>Learning Rate</td><td>0</td></tr><tr><td>Train Loss</td><td>1.42131</td></tr><tr><td>Val Loss</td><td>1.53283</td></tr><tr><td>Val Perplexity</td><td>4.63125</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">nanoGPT-MoE-2025-05-30_10-41-13</strong> at: <a href='https://wandb.ai/pathfinderkr/nanoGPT/runs/sfkj2vsd' target=\"_blank\">https://wandb.ai/pathfinderkr/nanoGPT/runs/sfkj2vsd</a><br> View project at: <a href='https://wandb.ai/pathfinderkr/nanoGPT' target=\"_blank\">https://wandb.ai/pathfinderkr/nanoGPT</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>./wandb/run-20250530_104118-sfkj2vsd/logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Inference",
   "id": "31f57a38b05be19b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T10:48:37.687886Z",
     "start_time": "2025-05-30T10:48:32.626372Z"
    }
   },
   "cell_type": "code",
   "source": [
    "user_prompt = \"To be, or not to be, that is the question\"\n",
    "input_ids = char_tokenizer.encode(user_prompt).unsqueeze(0).to(device)\n",
    "output = model.generate(\n",
    "    input_ids,\n",
    "    max_new_tokens=generation_config.max_new_tokens,\n",
    "    temperature=generation_config.temperature,\n",
    "    top_k=generation_config.top_k\n",
    ")\n",
    "response = char_tokenizer.decode(output[0].squeeze().cpu().numpy())"
   ],
   "id": "cc2a13ad05736a95",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T10:48:37.743120Z",
     "start_time": "2025-05-30T10:48:37.739724Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"=\" * 50)\n",
    "print(\"User prompt: \")\n",
    "print(user_prompt)\n",
    "print(\"-\" * 50)\n",
    "print(\"ğŸ¤– Model Response:\")\n",
    "print(response)"
   ],
   "id": "c78bf4aa4a5bec27",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "User prompt: \n",
      "To be, or not to be, that is the question\n",
      "--------------------------------------------------\n",
      "ğŸ¤– Model Response:\n",
      "To be, or not to be, that is the question.\n",
      "\n",
      "BRUTUS:\n",
      "I do, thank he's so one coil oath? Isable many was she\n",
      "as Hath run blord in't. For his every person; till wront they\n",
      "see to shall I have any natured of a matter's sacred\n",
      "with disposed the king to gates of knee, good strew,\n",
      "Which is news your bones on to prope ourselves,\n",
      "So well not them plotesy soul and Angelo alive,\n",
      "Porney, and he his nature petty is devost,\n",
      "Masters death in queen command to in the time\n",
      "That sun swigh-bove went that thou damn'dst,\n",
      "and the listle of this particular,\n",
      "And not live mine only furit day.\n",
      "I'll know what we that cried you?\n",
      "\n",
      "EDWARD:\n",
      "His dayst thou decking only good?\n",
      "\n",
      "BALTHASAR:\n",
      "Here mayor, be'n away;\n",
      "Which he hastes fearful Parience to die Coriolanus?\n",
      "\n",
      "HORTENSIO:\n",
      "But, give my great send of not countriar.\n",
      "\n",
      "GLOUCESTER:\n",
      "\n",
      "PeternIO:\n",
      "By I do your premoutation.\n",
      "\n",
      "QUEEN MARGARET:\n",
      "Unless that did country to your victor.\n",
      "\n",
      "GLOUCESTER:\n",
      "Dorrow, show now us I cannot foe.\n",
      "All farewell to purpoor us!\n",
      "\n",
      "LADY ANNE:\n",
      "Nay, false; this gentle.\n",
      "\n",
      "JULIET:\n",
      "Nay, as never matter\n"
     ]
    }
   ],
   "execution_count": 16
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
