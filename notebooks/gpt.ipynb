{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Importing libraries",
   "id": "36b2fa8101c30390"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T09:35:19.303740Z",
     "start_time": "2025-06-05T09:35:15.824574Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "from typing import Tuple\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import wandb\n",
    "from src.utils import set_seed, load_text, split_text, speedometer\n",
    "from src.config import ModelConfig, TrainConfig, GenerationConfig\n",
    "from src.tokenizer import CharTokenizer\n",
    "from models.GPT import GPT\n",
    "from src.train import Trainer"
   ],
   "id": "a38a265df86e4231",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T09:35:19.485530Z",
     "start_time": "2025-06-05T09:35:19.481098Z"
    }
   },
   "cell_type": "code",
   "source": [
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.append(PROJECT_ROOT)\n",
    "print(f\"PROJECT_ROOT: {PROJECT_ROOT}\")"
   ],
   "id": "70df4b9194f3773f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT: /workspace/PathFinder\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Configuration",
   "id": "1b632728e9a730d9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T09:35:19.547061Z",
     "start_time": "2025-06-05T09:35:19.544233Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_config = ModelConfig(\n",
    "    vocab_size=-1,\n",
    "    max_seq_len=128,\n",
    "    d_embed=128,\n",
    "    n_layers=4,\n",
    "    n_heads=4,\n",
    "    d_head=32,\n",
    "    d_ff=512,\n",
    "    rank=32\n",
    ")\n",
    "\n",
    "train_config = TrainConfig(\n",
    "    debug=True,\n",
    "    wandb_project=\"nanoGPT\",\n",
    "    model_name=\"nanoGPT\",\n",
    "    per_device_train_batch_size=512,\n",
    "    per_device_eval_batch_size=1024,\n",
    "    gradient_accumulation_steps=512 // 512,\n",
    "    num_train_epochs=1,\n",
    "    learning_rate=5e-3,\n",
    "    eval_steps=100,\n",
    "    mixed_precision=True,\n",
    "    matmul_precision=\"high\",\n",
    ")\n",
    "\n",
    "generation_config = GenerationConfig(\n",
    "    use_cache=True,\n",
    "    max_new_tokens=1000,\n",
    "    temperature=1.0,\n",
    "    top_k=50\n",
    ")"
   ],
   "id": "7321faac2fc60c61",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T09:35:20.361606Z",
     "start_time": "2025-06-05T09:35:19.605330Z"
    }
   },
   "cell_type": "code",
   "source": [
    "load_dotenv()\n",
    "wandb.login(key=os.environ.get(\"WANDB_API_KEY\"))"
   ],
   "id": "78c21c905da1750e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mpathfinderkr\u001B[0m to \u001B[32mhttps://api.wandb.ai\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Utils",
   "id": "a5aea71474607392"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Reproducibility",
   "id": "1a5ca12f86ee8ff4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T09:35:20.389738Z",
     "start_time": "2025-06-05T09:35:20.384954Z"
    }
   },
   "cell_type": "code",
   "source": "set_seed(train_config.seed)",
   "id": "1aee2436650dc3b4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set to 42\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Device",
   "id": "4d7ae71c3abae1ad"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T09:35:20.571508Z",
     "start_time": "2025-06-05T09:35:20.457154Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\")\n",
    "print(f\"Device: {torch.cuda.get_device_name(device)}\")\n",
    "torch.set_float32_matmul_precision(train_config.matmul_precision)  # Tensor Cores\n",
    "print(f\"MatMul Precision: {train_config.matmul_precision}\")"
   ],
   "id": "6fd52c7cdf9b9fff",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: NVIDIA RTX A6000\n",
      "MatMul Precision: high\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Dataset",
   "id": "881b3d83e0f9a02"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T09:35:20.601064Z",
     "start_time": "2025-06-05T09:35:20.596552Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset_path = os.path.join(PROJECT_ROOT, \"datasets/Shakespeare/shakespeare.txt\")\n",
    "shakespeare_text = load_text(dataset_path)"
   ],
   "id": "3fb5b3cb4c7caae3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded text data from /workspace/PathFinder/datasets/Shakespeare/shakespeare.txt (length: 1115394 characters).\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T09:35:20.670481Z",
     "start_time": "2025-06-05T09:35:20.667470Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if train_config.debug:\n",
    "    subset_shakespeare_text = shakespeare_text[:10000]\n",
    "    print(subset_shakespeare_text)\n",
    "    shakespeare_text = subset_shakespeare_text"
   ],
   "id": "891a7456f7efefb8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor citizens, the patricians good.\n",
      "What authority surfeits on would relieve us: if they\n",
      "would yield us but the superfluity, while it were\n",
      "wholesome, we might guess they relieved us humanely;\n",
      "but they think we are too dear: the leanness that\n",
      "afflicts us, the object of our misery, is as an\n",
      "inventory to particularise their abundance; our\n",
      "sufferance is a gain to them Let us revenge this with\n",
      "our pikes, ere we become rakes: for the gods know I\n",
      "speak this in hunger for bread, not in thirst for revenge.\n",
      "\n",
      "Second Citizen:\n",
      "Would you proceed especially against Caius Marcius?\n",
      "\n",
      "All:\n",
      "Against him first: he's a very dog to the commonalty.\n",
      "\n",
      "Second Citizen:\n",
      "Consider you what services he has done for his country?\n",
      "\n",
      "First Citizen:\n",
      "Very well; and could be content to give him good\n",
      "report fort, but that he pays himself with being proud.\n",
      "\n",
      "Second Citizen:\n",
      "Nay, but speak not maliciously.\n",
      "\n",
      "First Citizen:\n",
      "I say unto you, what he hath done famously, he did\n",
      "it to that end: though soft-conscienced men can be\n",
      "content to say it was for his country he did it to\n",
      "please his mother and to be partly proud; which he\n",
      "is, even till the altitude of his virtue.\n",
      "\n",
      "Second Citizen:\n",
      "What he cannot help in his nature, you account a\n",
      "vice in him. You must in no way say he is covetous.\n",
      "\n",
      "First Citizen:\n",
      "If I must not, I need not be barren of accusations;\n",
      "he hath faults, with surplus, to tire in repetition.\n",
      "What shouts are these? The other side o' the city\n",
      "is risen: why stay we prating here? to the Capitol!\n",
      "\n",
      "All:\n",
      "Come, come.\n",
      "\n",
      "First Citizen:\n",
      "Soft! who comes here?\n",
      "\n",
      "Second Citizen:\n",
      "Worthy Menenius Agrippa; one that hath always loved\n",
      "the people.\n",
      "\n",
      "First Citizen:\n",
      "He's one honest enough: would all the rest were so!\n",
      "\n",
      "MENENIUS:\n",
      "What work's, my countrymen, in hand? where go you\n",
      "With bats and clubs? The matter? speak, I pray you.\n",
      "\n",
      "First Citizen:\n",
      "Our business is not unknown to the senate; they have\n",
      "had inkling this fortnight what we intend to do,\n",
      "which now we'll show 'em in deeds. They say poor\n",
      "suitors have strong breaths: they shall know we\n",
      "have strong arms too.\n",
      "\n",
      "MENENIUS:\n",
      "Why, masters, my good friends, mine honest neighbours,\n",
      "Will you undo yourselves?\n",
      "\n",
      "First Citizen:\n",
      "We cannot, sir, we are undone already.\n",
      "\n",
      "MENENIUS:\n",
      "I tell you, friends, most charitable care\n",
      "Have the patricians of you. For your wants,\n",
      "Your suffering in this dearth, you may as well\n",
      "Strike at the heaven with your staves as lift them\n",
      "Against the Roman state, whose course will on\n",
      "The way it takes, cracking ten thousand curbs\n",
      "Of more strong link asunder than can ever\n",
      "Appear in your impediment. For the dearth,\n",
      "The gods, not the patricians, make it, and\n",
      "Your knees to them, not arms, must help. Alack,\n",
      "You are transported by calamity\n",
      "Thither where more attends you, and you slander\n",
      "The helms o' the state, who care for you like fathers,\n",
      "When you curse them as enemies.\n",
      "\n",
      "First Citizen:\n",
      "Care for us! True, indeed! They ne'er cared for us\n",
      "yet: suffer us to famish, and their store-houses\n",
      "crammed with grain; make edicts for usury, to\n",
      "support usurers; repeal daily any wholesome act\n",
      "established against the rich, and provide more\n",
      "piercing statutes daily, to chain up and restrain\n",
      "the poor. If the wars eat us not up, they will; and\n",
      "there's all the love they bear us.\n",
      "\n",
      "MENENIUS:\n",
      "Either you must\n",
      "Confess yourselves wondrous malicious,\n",
      "Or be accused of folly. I shall tell you\n",
      "A pretty tale: it may be you have heard it;\n",
      "But, since it serves my purpose, I will venture\n",
      "To stale 't a little more.\n",
      "\n",
      "First Citizen:\n",
      "Well, I'll hear it, sir: yet you must not think to\n",
      "fob off our disgrace with a tale: but, an 't please\n",
      "you, deliver.\n",
      "\n",
      "MENENIUS:\n",
      "There was a time when all the body's members\n",
      "Rebell'd against the belly, thus accused it:\n",
      "That only like a gulf it did remain\n",
      "I' the midst o' the body, idle and unactive,\n",
      "Still cupboarding the viand, never bearing\n",
      "Like labour with the rest, where the other instruments\n",
      "Did see and hear, devise, instruct, walk, feel,\n",
      "And, mutually participate, did minister\n",
      "Unto the appetite and affection common\n",
      "Of the whole body. The belly answer'd--\n",
      "\n",
      "First Citizen:\n",
      "Well, sir, what answer made the belly?\n",
      "\n",
      "MENENIUS:\n",
      "Sir, I shall tell you. With a kind of smile,\n",
      "Which ne'er came from the lungs, but even thus--\n",
      "For, look you, I may make the belly smile\n",
      "As well as speak--it tauntingly replied\n",
      "To the discontented members, the mutinous parts\n",
      "That envied his receipt; even so most fitly\n",
      "As you malign our senators for that\n",
      "They are not such as you.\n",
      "\n",
      "First Citizen:\n",
      "Your belly's answer? What!\n",
      "The kingly-crowned head, the vigilant eye,\n",
      "The counsellor heart, the arm our soldier,\n",
      "Our steed the leg, the tongue our trumpeter.\n",
      "With other muniments and petty helps\n",
      "In this our fabric, if that they--\n",
      "\n",
      "MENENIUS:\n",
      "What then?\n",
      "'Fore me, this fellow speaks! What then? what then?\n",
      "\n",
      "First Citizen:\n",
      "Should by the cormorant belly be restrain'd,\n",
      "Who is the sink o' the body,--\n",
      "\n",
      "MENENIUS:\n",
      "Well, what then?\n",
      "\n",
      "First Citizen:\n",
      "The former agents, if they did complain,\n",
      "What could the belly answer?\n",
      "\n",
      "MENENIUS:\n",
      "I will tell you\n",
      "If you'll bestow a small--of what you have little--\n",
      "Patience awhile, you'll hear the belly's answer.\n",
      "\n",
      "First Citizen:\n",
      "Ye're long about it.\n",
      "\n",
      "MENENIUS:\n",
      "Note me this, good friend;\n",
      "Your most grave belly was deliberate,\n",
      "Not rash like his accusers, and thus answer'd:\n",
      "'True is it, my incorporate friends,' quoth he,\n",
      "'That I receive the general food at first,\n",
      "Which you do live upon; and fit it is,\n",
      "Because I am the store-house and the shop\n",
      "Of the whole body: but, if you do remember,\n",
      "I send it through the rivers of your blood,\n",
      "Even to the court, the heart, to the seat o' the brain;\n",
      "And, through the cranks and offices of man,\n",
      "The strongest nerves and small inferior veins\n",
      "From me receive that natural competency\n",
      "Whereby they live: and though that all at once,\n",
      "You, my good friends,'--this says the belly, mark me,--\n",
      "\n",
      "First Citizen:\n",
      "Ay, sir; well, well.\n",
      "\n",
      "MENENIUS:\n",
      "'Though all at once cannot\n",
      "See what I do deliver out to each,\n",
      "Yet I can make my audit up, that all\n",
      "From me do back receive the flour of all,\n",
      "And leave me but the bran.' What say you to't?\n",
      "\n",
      "First Citizen:\n",
      "It was an answer: how apply you this?\n",
      "\n",
      "MENENIUS:\n",
      "The senators of Rome are this good belly,\n",
      "And you the mutinous members; for examine\n",
      "Their counsels and their cares, digest things rightly\n",
      "Touching the weal o' the common, you shall find\n",
      "No public benefit which you receive\n",
      "But it proceeds or comes from them to you\n",
      "And no way from yourselves. What do you think,\n",
      "You, the great toe of this assembly?\n",
      "\n",
      "First Citizen:\n",
      "I the great toe! why the great toe?\n",
      "\n",
      "MENENIUS:\n",
      "For that, being one o' the lowest, basest, poorest,\n",
      "Of this most wise rebellion, thou go'st foremost:\n",
      "Thou rascal, that art worst in blood to run,\n",
      "Lead'st first to win some vantage.\n",
      "But make you ready your stiff bats and clubs:\n",
      "Rome and her rats are at the point of battle;\n",
      "The one side must have bale.\n",
      "Hail, noble Marcius!\n",
      "\n",
      "MARCIUS:\n",
      "Thanks. What's the matter, you dissentious rogues,\n",
      "That, rubbing the poor itch of your opinion,\n",
      "Make yourselves scabs?\n",
      "\n",
      "First Citizen:\n",
      "We have ever your good word.\n",
      "\n",
      "MARCIUS:\n",
      "He that will give good words to thee will flatter\n",
      "Beneath abhorring. What would you have, you curs,\n",
      "That like nor peace nor war? the one affrights you,\n",
      "The other makes you proud. He that trusts to you,\n",
      "Where he should find you lions, finds you hares;\n",
      "Where foxes, geese: you are no surer, no,\n",
      "Than is the coal of fire upon the ice,\n",
      "Or hailstone in the sun. Your virtue is\n",
      "To make him worthy whose offence subdues him\n",
      "And curse that justice did it.\n",
      "Who deserves greatness\n",
      "Deserves your hate; and your affections are\n",
      "A sick man's appetite, who desires most that\n",
      "Which would increase his evil. He that depends\n",
      "Upon your favours swims with fins of lead\n",
      "And hews down oaks with rushes. Hang ye! Trust Ye?\n",
      "With every minute you do change a mind,\n",
      "And call him noble that was now your hate,\n",
      "Him vile that was your garland. What's the matter,\n",
      "That in these several places of the city\n",
      "You cry against the noble senate, who,\n",
      "Under the gods, keep you in awe, which else\n",
      "Would feed on one another? What's their seeking?\n",
      "\n",
      "MENENIUS:\n",
      "For corn at their own rates; whereof, they say,\n",
      "The city is well stored.\n",
      "\n",
      "MARCIUS:\n",
      "Hang 'em! They say!\n",
      "They'll sit by the fire, and presume to know\n",
      "What's done i' the Capitol; who's like to rise,\n",
      "Who thrives and who declines; side factions\n",
      "and give out\n",
      "Conjectural marriages; making parties strong\n",
      "And feebling such as stand not in their liking\n",
      "Below their cobbled shoes. They say there's\n",
      "grain enough!\n",
      "Would the nobility lay aside their ruth,\n",
      "And let me use my sword, I'll make a quarry\n",
      "With thousands of these quarter'd slaves, as high\n",
      "As I could pick my lance.\n",
      "\n",
      "MENENIUS:\n",
      "Nay, these are almost thoroughly persuaded;\n",
      "For though abundantly they lack discretion,\n",
      "Yet are they passing cowardly. But, I beseech you,\n",
      "What says the other troop?\n",
      "\n",
      "MARCIUS:\n",
      "They are dissolved: hang 'em!\n",
      "They said they were an-hungry; sigh'd forth proverbs,\n",
      "That hunger broke stone walls, that dogs must eat,\n",
      "That meat was made for mouths, that the gods sent not\n",
      "Corn for the rich men only: with these shreds\n",
      "They vented their complainings; which being answer'd,\n",
      "And a petition granted them, a strange one--\n",
      "To break the heart of generosity,\n",
      "And make bold power look pale--they threw their caps\n",
      "As they would hang them on the horns o' the moon,\n",
      "Shouting their emulation.\n",
      "\n",
      "MENENIUS:\n",
      "What is granted them?\n",
      "\n",
      "MARCIUS:\n",
      "Five tribunes to defend their vulgar wisdoms,\n",
      "Of their own choice: one's Junius Brutus,\n",
      "Sicinius Velutus, and I know not--'Sdeath!\n",
      "The rabble should have first unroof'd the city,\n",
      "Ere so prevail'd with me: \n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Tokenizer",
   "id": "73942bc06caadbf9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T09:35:20.732646Z",
     "start_time": "2025-06-05T09:35:20.729309Z"
    }
   },
   "cell_type": "code",
   "source": [
    "char_tokenizer = CharTokenizer()\n",
    "char_tokenizer.build_vocab(text=shakespeare_text)\n",
    "vocab_path = os.path.join(PROJECT_ROOT, \"datasets/Shakespeare/vocab.json\")\n",
    "char_tokenizer.save_vocab(vocab_path)\n",
    "model_config.vocab_size = char_tokenizer.vocab_size"
   ],
   "id": "1422132939291d01",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 61\n",
      "Vocabulary saved to /workspace/PathFinder/datasets/Shakespeare/vocab.json.\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T09:35:20.796006Z",
     "start_time": "2025-06-05T09:35:20.793172Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if train_config.debug:\n",
    "    print(\"Vocabulary:\", char_tokenizer.char2idx)"
   ],
   "id": "28702519b26b8516",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: {'<|begin_of_text|>': 0, '<|end_of_text|>': 1, '<|UNK|>': 2, '<|PAD|>': 3, '\\n': 4, ' ': 5, '!': 6, \"'\": 7, ',': 8, '-': 9, '.': 10, ':': 11, ';': 12, '?': 13, 'A': 14, 'B': 15, 'C': 16, 'D': 17, 'E': 18, 'F': 19, 'H': 20, 'I': 21, 'J': 22, 'L': 23, 'M': 24, 'N': 25, 'O': 26, 'P': 27, 'R': 28, 'S': 29, 'T': 30, 'U': 31, 'V': 32, 'W': 33, 'Y': 34, 'a': 35, 'b': 36, 'c': 37, 'd': 38, 'e': 39, 'f': 40, 'g': 41, 'h': 42, 'i': 43, 'j': 44, 'k': 45, 'l': 46, 'm': 47, 'n': 48, 'o': 49, 'p': 50, 'q': 51, 'r': 52, 's': 53, 't': 54, 'u': 55, 'v': 56, 'w': 57, 'x': 58, 'y': 59, 'z': 60}\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Preprocessing",
   "id": "3e19cdb93ce1cca9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T09:35:20.861555Z",
     "start_time": "2025-06-05T09:35:20.858123Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_text, val_text = split_text(shakespeare_text, val_size=0.1)\n",
    "print(f\"Training text length: {len(train_text)} characters\")\n",
    "print(f\"Validation text length: {len(val_text)} characters\")"
   ],
   "id": "369661fd35cc5408",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training text length: 9000 characters\n",
      "Validation text length: 1000 characters\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T09:35:20.923492Z",
     "start_time": "2025-06-05T09:35:20.917642Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, text: str, tokenizer: CharTokenizer, max_seq_len: int):\n",
    "        self.encoded = tokenizer.encode(text)\n",
    "        self.max_seq_len = max_seq_len\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.encoded) - self.max_seq_len\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        input_ids = self.encoded[idx:idx + self.max_seq_len]\n",
    "        target_ids = self.encoded[idx + 1:idx + self.max_seq_len + 1]\n",
    "        return input_ids, target_ids\n",
    "\n",
    "def collate_fn(batch):\n",
    "    input_ids = torch.stack([item[0] for item in batch])\n",
    "    target_ids = torch.stack([item[1] for item in batch])\n",
    "    return {\"input_ids\": input_ids, \"target_ids\": target_ids}\n",
    "\n",
    "train_dataset = TextDataset(train_text, char_tokenizer, model_config.max_seq_len)\n",
    "val_dataset = TextDataset(val_text, char_tokenizer, model_config.max_seq_len)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    collate_fn=collate_fn,\n",
    "    batch_size=train_config.per_device_eval_batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    collate_fn=collate_fn,\n",
    "    batch_size=train_config.per_device_eval_batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=4\n",
    ")"
   ],
   "id": "ade0a4f3f06bc47e",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T09:35:21.120222Z",
     "start_time": "2025-06-05T09:35:20.981578Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if train_config.debug:\n",
    "    sample_batch = next(iter(train_loader))\n",
    "    print(f\"Sample input IDs: {sample_batch['input_ids'][0]}\")\n",
    "    print(f\"Sample target IDs: {sample_batch['target_ids'][0]}\")"
   ],
   "id": "bd0090591cadc29e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample input IDs: tensor([10,  4,  4, 14, 46, 46, 11,  4, 33, 39,  5, 45, 48, 49, 57,  7, 54,  8,\n",
      "         5, 57, 39,  5, 45, 48, 49, 57,  7, 54, 10,  4,  4, 19, 43, 52, 53, 54,\n",
      "         5, 16, 43, 54, 43, 60, 39, 48, 11,  4, 23, 39, 54,  5, 55, 53,  5, 45,\n",
      "        43, 46, 46,  5, 42, 43, 47,  8,  5, 35, 48, 38,  5, 57, 39,  7, 46, 46,\n",
      "         5, 42, 35, 56, 39,  5, 37, 49, 52, 48,  5, 35, 54,  5, 49, 55, 52,  5,\n",
      "        49, 57, 48,  5, 50, 52, 43, 37, 39, 10,  4, 21, 53,  7, 54,  5, 35,  5,\n",
      "        56, 39, 52, 38, 43, 37, 54, 13,  4,  4, 14, 46, 46, 11,  4, 25, 49,  5,\n",
      "        47, 49])\n",
      "Sample target IDs: tensor([ 4,  4, 14, 46, 46, 11,  4, 33, 39,  5, 45, 48, 49, 57,  7, 54,  8,  5,\n",
      "        57, 39,  5, 45, 48, 49, 57,  7, 54, 10,  4,  4, 19, 43, 52, 53, 54,  5,\n",
      "        16, 43, 54, 43, 60, 39, 48, 11,  4, 23, 39, 54,  5, 55, 53,  5, 45, 43,\n",
      "        46, 46,  5, 42, 43, 47,  8,  5, 35, 48, 38,  5, 57, 39,  7, 46, 46,  5,\n",
      "        42, 35, 56, 39,  5, 37, 49, 52, 48,  5, 35, 54,  5, 49, 55, 52,  5, 49,\n",
      "        57, 48,  5, 50, 52, 43, 37, 39, 10,  4, 21, 53,  7, 54,  5, 35,  5, 56,\n",
      "        39, 52, 38, 43, 37, 54, 13,  4,  4, 14, 46, 46, 11,  4, 25, 49,  5, 47,\n",
      "        49, 52])\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model",
   "id": "c7426d2c0a176973"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T09:35:22.840886Z",
     "start_time": "2025-06-05T09:35:21.138071Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize the model\n",
    "model = GPT(model_config).to(device)\n",
    "model = torch.compile(model)\n",
    "print(model)\n",
    "print(f\"Number of parameters: {model.num_params() / 1e6:.2f}M\")"
   ],
   "id": "2d25545316ca49d5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OptimizedModule(\n",
      "  (_orig_mod): GPT(\n",
      "    (token_embedding): Embedding(61, 128)\n",
      "    (positional_encoding): Embedding(128, 128)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (blocks): ModuleList(\n",
      "      (0-3): 4 x Block(\n",
      "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): MultiHeadAttention(\n",
      "          (Wq): Linear(in_features=128, out_features=32, bias=False)\n",
      "          (Wkv_down): Linear(in_features=128, out_features=32, bias=False)\n",
      "          (Wk_up): Linear(in_features=32, out_features=128, bias=False)\n",
      "          (Wv_up): Linear(in_features=32, out_features=128, bias=False)\n",
      "          (out_proj): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): FeedForward(\n",
      "          (fc1): Linear(in_features=128, out_features=512, bias=False)\n",
      "          (activation): GELU(approximate='none')\n",
      "          (fc2): Linear(in_features=512, out_features=128, bias=False)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "    (lm_head): Linear(in_features=128, out_features=61, bias=False)\n",
      "  )\n",
      ")\n",
      "Number of parameters: 0.67M\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Training",
   "id": "bbe1c76409605d58"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T09:35:26.835614Z",
     "start_time": "2025-06-05T09:35:22.867927Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_config=train_config,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    device=device,\n",
    "    master_process=True\n",
    ")\n",
    "trainer.train()"
   ],
   "id": "df06c866b6549d28",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/workspace/PathFinder/wandb/run-20250605_093522-pkbjvig3</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/pathfinderkr/nanoGPT/runs/pkbjvig3' target=\"_blank\">nanoGPT-2025-06-05_09-35-18</a></strong> to <a href='https://wandb.ai/pathfinderkr/nanoGPT' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/pathfinderkr/nanoGPT' target=\"_blank\">https://wandb.ai/pathfinderkr/nanoGPT</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/pathfinderkr/nanoGPT/runs/pkbjvig3' target=\"_blank\">https://wandb.ai/pathfinderkr/nanoGPT/runs/pkbjvig3</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/9 [00:00<?, ?it/s]E0605 09:35:24.021000 48894 site-packages/torch/_subclasses/fake_tensor.py:2017] [0/0] failed while attempting to run meta for aten.view.default\n",
      "E0605 09:35:24.021000 48894 site-packages/torch/_subclasses/fake_tensor.py:2017] [0/0] Traceback (most recent call last):\n",
      "E0605 09:35:24.021000 48894 site-packages/torch/_subclasses/fake_tensor.py:2017] [0/0]   File \"/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py\", line 2013, in _dispatch_impl\n",
      "E0605 09:35:24.021000 48894 site-packages/torch/_subclasses/fake_tensor.py:2017] [0/0]     r = func(*args, **kwargs)\n",
      "E0605 09:35:24.021000 48894 site-packages/torch/_subclasses/fake_tensor.py:2017] [0/0]         ^^^^^^^^^^^^^^^^^^^^^\n",
      "E0605 09:35:24.021000 48894 site-packages/torch/_subclasses/fake_tensor.py:2017] [0/0]   File \"/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/_ops.py\", line 716, in __call__\n",
      "E0605 09:35:24.021000 48894 site-packages/torch/_subclasses/fake_tensor.py:2017] [0/0]     return self._op(*args, **kwargs)\n",
      "E0605 09:35:24.021000 48894 site-packages/torch/_subclasses/fake_tensor.py:2017] [0/0]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "E0605 09:35:24.021000 48894 site-packages/torch/_subclasses/fake_tensor.py:2017] [0/0]   File \"/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/_refs/__init__.py\", line 4591, in view\n",
      "E0605 09:35:24.021000 48894 site-packages/torch/_subclasses/fake_tensor.py:2017] [0/0]     return _reshape_view_helper(a, *shape, allow_copy=False)\n",
      "E0605 09:35:24.021000 48894 site-packages/torch/_subclasses/fake_tensor.py:2017] [0/0]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "E0605 09:35:24.021000 48894 site-packages/torch/_subclasses/fake_tensor.py:2017] [0/0]   File \"/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/_refs/__init__.py\", line 3659, in _reshape_view_helper\n",
      "E0605 09:35:24.021000 48894 site-packages/torch/_subclasses/fake_tensor.py:2017] [0/0]     shape = utils.infer_size(shape, a.numel())\n",
      "E0605 09:35:24.021000 48894 site-packages/torch/_subclasses/fake_tensor.py:2017] [0/0]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "E0605 09:35:24.021000 48894 site-packages/torch/_subclasses/fake_tensor.py:2017] [0/0]   File \"/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/_prims_common/__init__.py\", line 901, in infer_size\n",
      "E0605 09:35:24.021000 48894 site-packages/torch/_subclasses/fake_tensor.py:2017] [0/0]     torch._check(\n",
      "E0605 09:35:24.021000 48894 site-packages/torch/_subclasses/fake_tensor.py:2017] [0/0]   File \"/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/__init__.py\", line 1564, in _check\n",
      "E0605 09:35:24.021000 48894 site-packages/torch/_subclasses/fake_tensor.py:2017] [0/0]     _check_with(RuntimeError, cond, message)\n",
      "E0605 09:35:24.021000 48894 site-packages/torch/_subclasses/fake_tensor.py:2017] [0/0]   File \"/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/__init__.py\", line 1546, in _check_with\n",
      "E0605 09:35:24.021000 48894 site-packages/torch/_subclasses/fake_tensor.py:2017] [0/0]     raise error_type(message_evaluated)\n",
      "E0605 09:35:24.021000 48894 site-packages/torch/_subclasses/fake_tensor.py:2017] [0/0] RuntimeError: shape '[1024, 128, 4, 32]' is invalid for input of size 4194304\n"
     ]
    },
    {
     "ename": "TorchRuntimeError",
     "evalue": "Failed running call_method view(*(FakeTensor(..., device='cuda:0', size=(1024, 128, 32), dtype=torch.bfloat16,\n           grad_fn=<ViewBackward0>), 1024, 128, 4, 32), **{}):\nshape '[1024, 128, 4, 32]' is invalid for input of size 4194304\n\nfrom user code:\n   File \"/workspace/PathFinder/models/GPT.py\", line 337, in forward\n    x, kv_cache_layer = block(x, kv_cache=kv_cache[layer_idx])                  # [batch_size, seq_len, d_embed]\n  File \"/workspace/PathFinder/models/GPT.py\", line 274, in forward\n    attn_out, new_kv_cache = self.attn(x, kv_cache=kv_cache)\n  File \"/workspace/PathFinder/models/GPT.py\", line 90, in forward\n    q = q.view(batch_size, seq_len, self.config.n_heads, self.config.d_head).transpose(1, 2)\n\nSet TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n\n\nYou can suppress this exception and fall back to eager by setting:\n    import torch._dynamo\n    torch._dynamo.config.suppress_errors = True\n",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mTorchRuntimeError\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[15]\u001B[39m\u001B[32m, line 9\u001B[39m\n\u001B[32m      1\u001B[39m trainer = Trainer(\n\u001B[32m      2\u001B[39m     model=model,\n\u001B[32m      3\u001B[39m     train_config=train_config,\n\u001B[32m   (...)\u001B[39m\u001B[32m      7\u001B[39m     master_process=\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m      8\u001B[39m )\n\u001B[32m----> \u001B[39m\u001B[32m9\u001B[39m \u001B[43mtrainer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/workspace/PathFinder/src/train.py:82\u001B[39m, in \u001B[36mTrainer.train\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m     79\u001B[39m target_ids = batch[\u001B[33m\"\u001B[39m\u001B[33mtarget_ids\u001B[39m\u001B[33m\"\u001B[39m].to(\u001B[38;5;28mself\u001B[39m.device)\n\u001B[32m     81\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m.ctx:\n\u001B[32m---> \u001B[39m\u001B[32m82\u001B[39m     outputs, loss, _ = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget_ids\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     83\u001B[39m loss = loss / \u001B[38;5;28mself\u001B[39m.train_config.gradient_accumulation_steps\n\u001B[32m     84\u001B[39m loss.backward()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1734\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1735\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1736\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/nn/modules/module.py:1844\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1841\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m inner()\n\u001B[32m   1843\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1844\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43minner\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1845\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[32m   1846\u001B[39m     \u001B[38;5;66;03m# run always called hooks if they have not already been run\u001B[39;00m\n\u001B[32m   1847\u001B[39m     \u001B[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001B[39;00m\n\u001B[32m   1848\u001B[39m     \u001B[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001B[39;00m\n\u001B[32m   1849\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m hook_id, hook \u001B[38;5;129;01min\u001B[39;00m _global_forward_hooks.items():\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/nn/modules/module.py:1790\u001B[39m, in \u001B[36mModule._call_impl.<locals>.inner\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m   1787\u001B[39m     bw_hook = BackwardHook(\u001B[38;5;28mself\u001B[39m, full_backward_hooks, backward_pre_hooks)\n\u001B[32m   1788\u001B[39m     args = bw_hook.setup_input_hook(args)\n\u001B[32m-> \u001B[39m\u001B[32m1790\u001B[39m result = \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1791\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks:\n\u001B[32m   1792\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m hook_id, hook \u001B[38;5;129;01min\u001B[39;00m (\n\u001B[32m   1793\u001B[39m         *_global_forward_hooks.items(),\n\u001B[32m   1794\u001B[39m         *\u001B[38;5;28mself\u001B[39m._forward_hooks.items(),\n\u001B[32m   1795\u001B[39m     ):\n\u001B[32m   1796\u001B[39m         \u001B[38;5;66;03m# mark that always called hook is run\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:465\u001B[39m, in \u001B[36m_TorchDynamoContext.__call__.<locals>._fn\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    460\u001B[39m saved_dynamic_layer_stack_depth = (\n\u001B[32m    461\u001B[39m     torch._C._functorch.get_dynamic_layer_stack_depth()\n\u001B[32m    462\u001B[39m )\n\u001B[32m    464\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m465\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    466\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    467\u001B[39m     \u001B[38;5;66;03m# Restore the dynamic layer stack depth if necessary.\u001B[39;00m\n\u001B[32m    468\u001B[39m     torch._C._functorch.pop_dynamic_layer_stack_and_undo_to_depth(\n\u001B[32m    469\u001B[39m         saved_dynamic_layer_stack_depth\n\u001B[32m    470\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1734\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1735\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1736\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1742\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1743\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1744\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1745\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1746\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1747\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1749\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1750\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:1269\u001B[39m, in \u001B[36mCatchErrorsWrapper.__call__\u001B[39m\u001B[34m(self, frame, cache_entry, frame_state)\u001B[39m\n\u001B[32m   1263\u001B[39m             \u001B[38;5;28;01mreturn\u001B[39;00m hijacked_callback(\n\u001B[32m   1264\u001B[39m                 frame, cache_entry, \u001B[38;5;28mself\u001B[39m.hooks, frame_state\n\u001B[32m   1265\u001B[39m             )\n\u001B[32m   1267\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m compile_lock, _disable_current_modes():\n\u001B[32m   1268\u001B[39m     \u001B[38;5;66;03m# skip=1: skip this frame\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1269\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_torchdynamo_orig_callable\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1270\u001B[39m \u001B[43m        \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcache_entry\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mhooks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe_state\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mskip\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m1\u001B[39;49m\n\u001B[32m   1271\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:1064\u001B[39m, in \u001B[36mConvertFrame.__call__\u001B[39m\u001B[34m(self, frame, cache_entry, hooks, frame_state, skip)\u001B[39m\n\u001B[32m   1062\u001B[39m counters[\u001B[33m\"\u001B[39m\u001B[33mframes\u001B[39m\u001B[33m\"\u001B[39m][\u001B[33m\"\u001B[39m\u001B[33mtotal\u001B[39m\u001B[33m\"\u001B[39m] += \u001B[32m1\u001B[39m\n\u001B[32m   1063\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1064\u001B[39m     result = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_inner_convert\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1065\u001B[39m \u001B[43m        \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcache_entry\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhooks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe_state\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mskip\u001B[49m\u001B[43m=\u001B[49m\u001B[43mskip\u001B[49m\u001B[43m \u001B[49m\u001B[43m+\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m1\u001B[39;49m\n\u001B[32m   1066\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1067\u001B[39m     counters[\u001B[33m\"\u001B[39m\u001B[33mframes\u001B[39m\u001B[33m\"\u001B[39m][\u001B[33m\"\u001B[39m\u001B[33mok\u001B[39m\u001B[33m\"\u001B[39m] += \u001B[32m1\u001B[39m\n\u001B[32m   1068\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:526\u001B[39m, in \u001B[36mConvertFrameAssert.__call__\u001B[39m\u001B[34m(self, frame, cache_entry, hooks, frame_state, skip)\u001B[39m\n\u001B[32m    510\u001B[39m compile_id = CompileId(frame_id, frame_compile_id)\n\u001B[32m    512\u001B[39m signpost_event(\n\u001B[32m    513\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mdynamo\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    514\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33m_convert_frame_assert._compile\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m    523\u001B[39m     },\n\u001B[32m    524\u001B[39m )\n\u001B[32m--> \u001B[39m\u001B[32m526\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_compile\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    527\u001B[39m \u001B[43m    \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m.\u001B[49m\u001B[43mf_code\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    528\u001B[39m \u001B[43m    \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m.\u001B[49m\u001B[43mf_globals\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    529\u001B[39m \u001B[43m    \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m.\u001B[49m\u001B[43mf_locals\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    530\u001B[39m \u001B[43m    \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m.\u001B[49m\u001B[43mf_builtins\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    531\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_torchdynamo_orig_callable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    532\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_one_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    533\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_export\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    534\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_export_constraints\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    535\u001B[39m \u001B[43m    \u001B[49m\u001B[43mhooks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    536\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcache_entry\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    537\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcache_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    538\u001B[39m \u001B[43m    \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    539\u001B[39m \u001B[43m    \u001B[49m\u001B[43mframe_state\u001B[49m\u001B[43m=\u001B[49m\u001B[43mframe_state\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    540\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcompile_id\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcompile_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    541\u001B[39m \u001B[43m    \u001B[49m\u001B[43mskip\u001B[49m\u001B[43m=\u001B[49m\u001B[43mskip\u001B[49m\u001B[43m \u001B[49m\u001B[43m+\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    542\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:924\u001B[39m, in \u001B[36m_compile\u001B[39m\u001B[34m(code, globals, locals, builtins, compiler_fn, one_graph, export, export_constraints, hooks, cache_entry, cache_size, frame, frame_state, compile_id, skip)\u001B[39m\n\u001B[32m    922\u001B[39m guarded_code = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    923\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m924\u001B[39m     guarded_code = \u001B[43mcompile_inner\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mone_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhooks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtransform\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    925\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m guarded_code\n\u001B[32m    926\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:666\u001B[39m, in \u001B[36m_compile.<locals>.compile_inner\u001B[39m\u001B[34m(code, one_graph, hooks, transform)\u001B[39m\n\u001B[32m    664\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m dynamo_timed(\u001B[33m\"\u001B[39m\u001B[33m_compile.compile_inner\u001B[39m\u001B[33m\"\u001B[39m, phase_name=\u001B[33m\"\u001B[39m\u001B[33mentire_frame_compile\u001B[39m\u001B[33m\"\u001B[39m):\n\u001B[32m    665\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m CompileTimeInstructionCounter.record():\n\u001B[32m--> \u001B[39m\u001B[32m666\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_compile_inner\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mone_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhooks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtransform\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/_utils_internal.py:87\u001B[39m, in \u001B[36mcompile_time_strobelight_meta.<locals>.compile_time_strobelight_meta_inner.<locals>.wrapper_function\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m     84\u001B[39m     kwargs[\u001B[33m\"\u001B[39m\u001B[33mskip\u001B[39m\u001B[33m\"\u001B[39m] = kwargs[\u001B[33m\"\u001B[39m\u001B[33mskip\u001B[39m\u001B[33m\"\u001B[39m] + \u001B[32m1\u001B[39m\n\u001B[32m     86\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m StrobelightCompileTimeProfiler.enabled:\n\u001B[32m---> \u001B[39m\u001B[32m87\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunction\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     89\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m StrobelightCompileTimeProfiler.profile_compile_time(\n\u001B[32m     90\u001B[39m     function, phase_name, *args, **kwargs\n\u001B[32m     91\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:699\u001B[39m, in \u001B[36m_compile.<locals>._compile_inner\u001B[39m\u001B[34m(code, one_graph, hooks, transform)\u001B[39m\n\u001B[32m    697\u001B[39m CompileContext.get().attempt = attempt\n\u001B[32m    698\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m699\u001B[39m     out_code = \u001B[43mtransform_code_object\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtransform\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    700\u001B[39m     \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[32m    701\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m exc.RestartAnalysis \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/_dynamo/bytecode_transformation.py:1322\u001B[39m, in \u001B[36mtransform_code_object\u001B[39m\u001B[34m(code, transformations, safe)\u001B[39m\n\u001B[32m   1319\u001B[39m instructions = cleaned_instructions(code, safe)\n\u001B[32m   1320\u001B[39m propagate_line_nums(instructions)\n\u001B[32m-> \u001B[39m\u001B[32m1322\u001B[39m \u001B[43mtransformations\u001B[49m\u001B[43m(\u001B[49m\u001B[43minstructions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcode_options\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1323\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m clean_and_assemble_instructions(instructions, keys, code_options)[\u001B[32m1\u001B[39m]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:219\u001B[39m, in \u001B[36mpreserve_global_state.<locals>._fn\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    215\u001B[39m exit_stack.enter_context(\n\u001B[32m    216\u001B[39m     torch.fx._symbolic_trace._maybe_revert_all_patches()\n\u001B[32m    217\u001B[39m )\n\u001B[32m    218\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m219\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    220\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    221\u001B[39m     cleanup.close()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:634\u001B[39m, in \u001B[36m_compile.<locals>.transform\u001B[39m\u001B[34m(instructions, code_options)\u001B[39m\n\u001B[32m    632\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    633\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m tracing(tracer.output.tracing_context), tracer.set_current_tx():\n\u001B[32m--> \u001B[39m\u001B[32m634\u001B[39m         \u001B[43mtracer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    635\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m exc.UnspecializeRestartAnalysis:\n\u001B[32m    636\u001B[39m     speculation_log.clear()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:2796\u001B[39m, in \u001B[36mInstructionTranslator.run\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   2795\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mrun\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m-> \u001B[39m\u001B[32m2796\u001B[39m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:983\u001B[39m, in \u001B[36mInstructionTranslatorBase.run\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    981\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    982\u001B[39m     \u001B[38;5;28mself\u001B[39m.output.push_tx(\u001B[38;5;28mself\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m983\u001B[39m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[32m    984\u001B[39m         \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[32m    985\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m BackendCompilerFailed:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:895\u001B[39m, in \u001B[36mInstructionTranslatorBase.step\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    892\u001B[39m \u001B[38;5;28mself\u001B[39m.update_block_stack(inst)\n\u001B[32m    894\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m895\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdispatch_table\u001B[49m\u001B[43m[\u001B[49m\u001B[43minst\u001B[49m\u001B[43m.\u001B[49m\u001B[43mopcode\u001B[49m\u001B[43m]\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minst\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    896\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m.output.should_exit\n\u001B[32m    897\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m exc.ObservedException \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:582\u001B[39m, in \u001B[36mbreak_graph_if_unsupported.<locals>.decorator.<locals>.wrapper\u001B[39m\u001B[34m(self, inst)\u001B[39m\n\u001B[32m    580\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_graph_break(\u001B[38;5;28mself\u001B[39m, inst, speculation.reason)\n\u001B[32m    581\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m582\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43minner_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minst\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    583\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m Unsupported \u001B[38;5;28;01mas\u001B[39;00m excp:\n\u001B[32m    584\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.generic_context_manager_depth > \u001B[32m0\u001B[39m:\n\u001B[32m    585\u001B[39m         \u001B[38;5;66;03m# We don't support graph break under GenericContextWrappingVariable,\u001B[39;00m\n\u001B[32m    586\u001B[39m         \u001B[38;5;66;03m# If there is, we roll back to the checkpoint and fall back.\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:2279\u001B[39m, in \u001B[36mInstructionTranslatorBase.CALL\u001B[39m\u001B[34m(self, inst)\u001B[39m\n\u001B[32m   2277\u001B[39m \u001B[38;5;129m@break_graph_if_unsupported\u001B[39m(push=\u001B[32m1\u001B[39m)\n\u001B[32m   2278\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mCALL\u001B[39m(\u001B[38;5;28mself\u001B[39m, inst):\n\u001B[32m-> \u001B[39m\u001B[32m2279\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43minst\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:2273\u001B[39m, in \u001B[36mInstructionTranslatorBase._call\u001B[39m\u001B[34m(self, inst, call_kw)\u001B[39m\n\u001B[32m   2268\u001B[39m     kwargs = {}\n\u001B[32m   2270\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m   2271\u001B[39m     \u001B[38;5;66;03m# if call_function fails, need to set kw_names to None, otherwise\u001B[39;00m\n\u001B[32m   2272\u001B[39m     \u001B[38;5;66;03m# a subsequent call may have self.kw_names set to an old value\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m2273\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2274\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m   2275\u001B[39m     \u001B[38;5;28mself\u001B[39m.kw_names = \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:830\u001B[39m, in \u001B[36mInstructionTranslatorBase.call_function\u001B[39m\u001B[34m(self, fn, args, kwargs)\u001B[39m\n\u001B[32m    828\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m inner_fn \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mcallable\u001B[39m(inner_fn) \u001B[38;5;129;01mand\u001B[39;00m is_forbidden(inner_fn):\n\u001B[32m    829\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mAttempt to trace forbidden callable \u001B[39m\u001B[38;5;132;01m{\u001B[39;00minner_fn\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m830\u001B[39m \u001B[38;5;28mself\u001B[39m.push(\u001B[43mfn\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/_dynamo/variables/nn_module.py:899\u001B[39m, in \u001B[36mUnspecializedNNModuleVariable.call_function\u001B[39m\u001B[34m(self, tx, args, kwargs)\u001B[39m\n\u001B[32m    891\u001B[39m ctx = (\n\u001B[32m    892\u001B[39m     record_nn_module_stack(\n\u001B[32m    893\u001B[39m         \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(mod)), \u001B[38;5;28mself\u001B[39m.get_nn_module_stack_source(), tx, mod\n\u001B[32m   (...)\u001B[39m\u001B[32m    896\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m nullcontext()\n\u001B[32m    897\u001B[39m )\n\u001B[32m    898\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m ctx:\n\u001B[32m--> \u001B[39m\u001B[32m899\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mvariables\u001B[49m\u001B[43m.\u001B[49m\u001B[43mUserFunctionVariable\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msource\u001B[49m\u001B[43m=\u001B[49m\u001B[43msource\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    900\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[43m+\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\n\u001B[32m    901\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/_dynamo/variables/functions.py:324\u001B[39m, in \u001B[36mUserFunctionVariable.call_function\u001B[39m\u001B[34m(self, tx, args, kwargs)\u001B[39m\n\u001B[32m    319\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.is_constant:\n\u001B[32m    320\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m invoke_and_store_as_constant(\n\u001B[32m    321\u001B[39m         tx, \u001B[38;5;28mself\u001B[39m.fn, \u001B[38;5;28mself\u001B[39m.get_name(), args, kwargs\n\u001B[32m    322\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m324\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/_dynamo/variables/functions.py:111\u001B[39m, in \u001B[36mBaseUserFunctionVariable.call_function\u001B[39m\u001B[34m(self, tx, args, kwargs)\u001B[39m\n\u001B[32m    105\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mcall_function\u001B[39m(\n\u001B[32m    106\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    107\u001B[39m     tx: \u001B[33m\"\u001B[39m\u001B[33mInstructionTranslator\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    108\u001B[39m     args: \u001B[33m\"\u001B[39m\u001B[33mList[VariableTracker]\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    109\u001B[39m     kwargs: \u001B[33m\"\u001B[39m\u001B[33mDict[str, VariableTracker]\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    110\u001B[39m ) -> \u001B[33m\"\u001B[39m\u001B[33mVariableTracker\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m--> \u001B[39m\u001B[32m111\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtx\u001B[49m\u001B[43m.\u001B[49m\u001B[43minline_user_function_return\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43m*\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mself_args\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:836\u001B[39m, in \u001B[36mInstructionTranslatorBase.inline_user_function_return\u001B[39m\u001B[34m(self, fn, args, kwargs)\u001B[39m\n\u001B[32m    832\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34minline_user_function_return\u001B[39m(\u001B[38;5;28mself\u001B[39m, fn, args, kwargs):\n\u001B[32m    833\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    834\u001B[39m \u001B[33;03m    A call to some user defined function by inlining it.\u001B[39;00m\n\u001B[32m    835\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m836\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mInliningInstructionTranslator\u001B[49m\u001B[43m.\u001B[49m\u001B[43minline_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:3011\u001B[39m, in \u001B[36mInliningInstructionTranslator.inline_call\u001B[39m\u001B[34m(cls, parent, func, args, kwargs)\u001B[39m\n\u001B[32m   3008\u001B[39m \u001B[38;5;129m@classmethod\u001B[39m\n\u001B[32m   3009\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34minline_call\u001B[39m(\u001B[38;5;28mcls\u001B[39m, parent, func, args, kwargs):\n\u001B[32m   3010\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m patch.dict(counters, {\u001B[33m\"\u001B[39m\u001B[33munimplemented\u001B[39m\u001B[33m\"\u001B[39m: counters[\u001B[33m\"\u001B[39m\u001B[33minline_call\u001B[39m\u001B[33m\"\u001B[39m]}):\n\u001B[32m-> \u001B[39m\u001B[32m3011\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43minline_call_\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:3139\u001B[39m, in \u001B[36mInliningInstructionTranslator.inline_call_\u001B[39m\u001B[34m(parent, func, args, kwargs)\u001B[39m\n\u001B[32m   3137\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m   3138\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m strict_ctx:\n\u001B[32m-> \u001B[39m\u001B[32m3139\u001B[39m         \u001B[43mtracer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   3140\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m exc.ObservedException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m   3141\u001B[39m     msg = \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mObserved exception DURING INLING \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcode\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m : \u001B[39m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:983\u001B[39m, in \u001B[36mInstructionTranslatorBase.run\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    981\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    982\u001B[39m     \u001B[38;5;28mself\u001B[39m.output.push_tx(\u001B[38;5;28mself\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m983\u001B[39m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[32m    984\u001B[39m         \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[32m    985\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m BackendCompilerFailed:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:895\u001B[39m, in \u001B[36mInstructionTranslatorBase.step\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    892\u001B[39m \u001B[38;5;28mself\u001B[39m.update_block_stack(inst)\n\u001B[32m    894\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m895\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdispatch_table\u001B[49m\u001B[43m[\u001B[49m\u001B[43minst\u001B[49m\u001B[43m.\u001B[49m\u001B[43mopcode\u001B[49m\u001B[43m]\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minst\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    896\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m.output.should_exit\n\u001B[32m    897\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m exc.ObservedException \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:582\u001B[39m, in \u001B[36mbreak_graph_if_unsupported.<locals>.decorator.<locals>.wrapper\u001B[39m\u001B[34m(self, inst)\u001B[39m\n\u001B[32m    580\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_graph_break(\u001B[38;5;28mself\u001B[39m, inst, speculation.reason)\n\u001B[32m    581\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m582\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43minner_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minst\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    583\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m Unsupported \u001B[38;5;28;01mas\u001B[39;00m excp:\n\u001B[32m    584\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.generic_context_manager_depth > \u001B[32m0\u001B[39m:\n\u001B[32m    585\u001B[39m         \u001B[38;5;66;03m# We don't support graph break under GenericContextWrappingVariable,\u001B[39;00m\n\u001B[32m    586\u001B[39m         \u001B[38;5;66;03m# If there is, we roll back to the checkpoint and fall back.\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:2279\u001B[39m, in \u001B[36mInstructionTranslatorBase.CALL\u001B[39m\u001B[34m(self, inst)\u001B[39m\n\u001B[32m   2277\u001B[39m \u001B[38;5;129m@break_graph_if_unsupported\u001B[39m(push=\u001B[32m1\u001B[39m)\n\u001B[32m   2278\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mCALL\u001B[39m(\u001B[38;5;28mself\u001B[39m, inst):\n\u001B[32m-> \u001B[39m\u001B[32m2279\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43minst\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:2273\u001B[39m, in \u001B[36mInstructionTranslatorBase._call\u001B[39m\u001B[34m(self, inst, call_kw)\u001B[39m\n\u001B[32m   2268\u001B[39m     kwargs = {}\n\u001B[32m   2270\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m   2271\u001B[39m     \u001B[38;5;66;03m# if call_function fails, need to set kw_names to None, otherwise\u001B[39;00m\n\u001B[32m   2272\u001B[39m     \u001B[38;5;66;03m# a subsequent call may have self.kw_names set to an old value\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m2273\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2274\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m   2275\u001B[39m     \u001B[38;5;28mself\u001B[39m.kw_names = \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:830\u001B[39m, in \u001B[36mInstructionTranslatorBase.call_function\u001B[39m\u001B[34m(self, fn, args, kwargs)\u001B[39m\n\u001B[32m    828\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m inner_fn \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mcallable\u001B[39m(inner_fn) \u001B[38;5;129;01mand\u001B[39;00m is_forbidden(inner_fn):\n\u001B[32m    829\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mAttempt to trace forbidden callable \u001B[39m\u001B[38;5;132;01m{\u001B[39;00minner_fn\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m830\u001B[39m \u001B[38;5;28mself\u001B[39m.push(\u001B[43mfn\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/_dynamo/variables/lazy.py:156\u001B[39m, in \u001B[36m_create_realize_and_forward.<locals>.realize_and_forward\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m    154\u001B[39m \u001B[38;5;129m@functools\u001B[39m.wraps(\u001B[38;5;28mgetattr\u001B[39m(VariableTracker, name))\n\u001B[32m    155\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mrealize_and_forward\u001B[39m(\u001B[38;5;28mself\u001B[39m, *args, **kwargs):\n\u001B[32m--> \u001B[39m\u001B[32m156\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mrealize\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/_dynamo/variables/nn_module.py:899\u001B[39m, in \u001B[36mUnspecializedNNModuleVariable.call_function\u001B[39m\u001B[34m(self, tx, args, kwargs)\u001B[39m\n\u001B[32m    891\u001B[39m ctx = (\n\u001B[32m    892\u001B[39m     record_nn_module_stack(\n\u001B[32m    893\u001B[39m         \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(mod)), \u001B[38;5;28mself\u001B[39m.get_nn_module_stack_source(), tx, mod\n\u001B[32m   (...)\u001B[39m\u001B[32m    896\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m nullcontext()\n\u001B[32m    897\u001B[39m )\n\u001B[32m    898\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m ctx:\n\u001B[32m--> \u001B[39m\u001B[32m899\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mvariables\u001B[49m\u001B[43m.\u001B[49m\u001B[43mUserFunctionVariable\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msource\u001B[49m\u001B[43m=\u001B[49m\u001B[43msource\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    900\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[43m+\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\n\u001B[32m    901\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/_dynamo/variables/functions.py:324\u001B[39m, in \u001B[36mUserFunctionVariable.call_function\u001B[39m\u001B[34m(self, tx, args, kwargs)\u001B[39m\n\u001B[32m    319\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.is_constant:\n\u001B[32m    320\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m invoke_and_store_as_constant(\n\u001B[32m    321\u001B[39m         tx, \u001B[38;5;28mself\u001B[39m.fn, \u001B[38;5;28mself\u001B[39m.get_name(), args, kwargs\n\u001B[32m    322\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m324\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/_dynamo/variables/functions.py:111\u001B[39m, in \u001B[36mBaseUserFunctionVariable.call_function\u001B[39m\u001B[34m(self, tx, args, kwargs)\u001B[39m\n\u001B[32m    105\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mcall_function\u001B[39m(\n\u001B[32m    106\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    107\u001B[39m     tx: \u001B[33m\"\u001B[39m\u001B[33mInstructionTranslator\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    108\u001B[39m     args: \u001B[33m\"\u001B[39m\u001B[33mList[VariableTracker]\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    109\u001B[39m     kwargs: \u001B[33m\"\u001B[39m\u001B[33mDict[str, VariableTracker]\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    110\u001B[39m ) -> \u001B[33m\"\u001B[39m\u001B[33mVariableTracker\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m--> \u001B[39m\u001B[32m111\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtx\u001B[49m\u001B[43m.\u001B[49m\u001B[43minline_user_function_return\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43m*\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mself_args\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:836\u001B[39m, in \u001B[36mInstructionTranslatorBase.inline_user_function_return\u001B[39m\u001B[34m(self, fn, args, kwargs)\u001B[39m\n\u001B[32m    832\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34minline_user_function_return\u001B[39m(\u001B[38;5;28mself\u001B[39m, fn, args, kwargs):\n\u001B[32m    833\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    834\u001B[39m \u001B[33;03m    A call to some user defined function by inlining it.\u001B[39;00m\n\u001B[32m    835\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m836\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mInliningInstructionTranslator\u001B[49m\u001B[43m.\u001B[49m\u001B[43minline_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:3011\u001B[39m, in \u001B[36mInliningInstructionTranslator.inline_call\u001B[39m\u001B[34m(cls, parent, func, args, kwargs)\u001B[39m\n\u001B[32m   3008\u001B[39m \u001B[38;5;129m@classmethod\u001B[39m\n\u001B[32m   3009\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34minline_call\u001B[39m(\u001B[38;5;28mcls\u001B[39m, parent, func, args, kwargs):\n\u001B[32m   3010\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m patch.dict(counters, {\u001B[33m\"\u001B[39m\u001B[33munimplemented\u001B[39m\u001B[33m\"\u001B[39m: counters[\u001B[33m\"\u001B[39m\u001B[33minline_call\u001B[39m\u001B[33m\"\u001B[39m]}):\n\u001B[32m-> \u001B[39m\u001B[32m3011\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43minline_call_\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:3139\u001B[39m, in \u001B[36mInliningInstructionTranslator.inline_call_\u001B[39m\u001B[34m(parent, func, args, kwargs)\u001B[39m\n\u001B[32m   3137\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m   3138\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m strict_ctx:\n\u001B[32m-> \u001B[39m\u001B[32m3139\u001B[39m         \u001B[43mtracer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   3140\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m exc.ObservedException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m   3141\u001B[39m     msg = \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mObserved exception DURING INLING \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcode\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m : \u001B[39m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:983\u001B[39m, in \u001B[36mInstructionTranslatorBase.run\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    981\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    982\u001B[39m     \u001B[38;5;28mself\u001B[39m.output.push_tx(\u001B[38;5;28mself\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m983\u001B[39m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[32m    984\u001B[39m         \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[32m    985\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m BackendCompilerFailed:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:895\u001B[39m, in \u001B[36mInstructionTranslatorBase.step\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    892\u001B[39m \u001B[38;5;28mself\u001B[39m.update_block_stack(inst)\n\u001B[32m    894\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m895\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdispatch_table\u001B[49m\u001B[43m[\u001B[49m\u001B[43minst\u001B[49m\u001B[43m.\u001B[49m\u001B[43mopcode\u001B[49m\u001B[43m]\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minst\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    896\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m.output.should_exit\n\u001B[32m    897\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m exc.ObservedException \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:582\u001B[39m, in \u001B[36mbreak_graph_if_unsupported.<locals>.decorator.<locals>.wrapper\u001B[39m\u001B[34m(self, inst)\u001B[39m\n\u001B[32m    580\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_graph_break(\u001B[38;5;28mself\u001B[39m, inst, speculation.reason)\n\u001B[32m    581\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m582\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43minner_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minst\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    583\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m Unsupported \u001B[38;5;28;01mas\u001B[39;00m excp:\n\u001B[32m    584\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.generic_context_manager_depth > \u001B[32m0\u001B[39m:\n\u001B[32m    585\u001B[39m         \u001B[38;5;66;03m# We don't support graph break under GenericContextWrappingVariable,\u001B[39;00m\n\u001B[32m    586\u001B[39m         \u001B[38;5;66;03m# If there is, we roll back to the checkpoint and fall back.\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:2279\u001B[39m, in \u001B[36mInstructionTranslatorBase.CALL\u001B[39m\u001B[34m(self, inst)\u001B[39m\n\u001B[32m   2277\u001B[39m \u001B[38;5;129m@break_graph_if_unsupported\u001B[39m(push=\u001B[32m1\u001B[39m)\n\u001B[32m   2278\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mCALL\u001B[39m(\u001B[38;5;28mself\u001B[39m, inst):\n\u001B[32m-> \u001B[39m\u001B[32m2279\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43minst\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:2273\u001B[39m, in \u001B[36mInstructionTranslatorBase._call\u001B[39m\u001B[34m(self, inst, call_kw)\u001B[39m\n\u001B[32m   2268\u001B[39m     kwargs = {}\n\u001B[32m   2270\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m   2271\u001B[39m     \u001B[38;5;66;03m# if call_function fails, need to set kw_names to None, otherwise\u001B[39;00m\n\u001B[32m   2272\u001B[39m     \u001B[38;5;66;03m# a subsequent call may have self.kw_names set to an old value\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m2273\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2274\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m   2275\u001B[39m     \u001B[38;5;28mself\u001B[39m.kw_names = \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:830\u001B[39m, in \u001B[36mInstructionTranslatorBase.call_function\u001B[39m\u001B[34m(self, fn, args, kwargs)\u001B[39m\n\u001B[32m    828\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m inner_fn \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mcallable\u001B[39m(inner_fn) \u001B[38;5;129;01mand\u001B[39;00m is_forbidden(inner_fn):\n\u001B[32m    829\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mAttempt to trace forbidden callable \u001B[39m\u001B[38;5;132;01m{\u001B[39;00minner_fn\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m830\u001B[39m \u001B[38;5;28mself\u001B[39m.push(\u001B[43mfn\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/_dynamo/variables/misc.py:1024\u001B[39m, in \u001B[36mGetAttrVariable.call_function\u001B[39m\u001B[34m(self, tx, args, kwargs)\u001B[39m\n\u001B[32m   1018\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mcall_function\u001B[39m(\n\u001B[32m   1019\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   1020\u001B[39m     tx: \u001B[33m\"\u001B[39m\u001B[33mInstructionTranslator\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m   1021\u001B[39m     args: \u001B[33m\"\u001B[39m\u001B[33mList[VariableTracker]\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m   1022\u001B[39m     kwargs: \u001B[33m\"\u001B[39m\u001B[33mDict[str, VariableTracker]\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m   1023\u001B[39m ) -> \u001B[33m\"\u001B[39m\u001B[33mVariableTracker\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m-> \u001B[39m\u001B[32m1024\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcall_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/_dynamo/variables/tensor.py:535\u001B[39m, in \u001B[36mTensorVariable.call_method\u001B[39m\u001B[34m(self, tx, name, args, kwargs)\u001B[39m\n\u001B[32m    531\u001B[39m         unimplemented(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33munhandled args for \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m    533\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mbuilder\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m wrap_fx_proxy\n\u001B[32m--> \u001B[39m\u001B[32m535\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mwrap_fx_proxy\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    536\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    537\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtx\u001B[49m\u001B[43m.\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcreate_proxy\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    538\u001B[39m \u001B[43m        \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mcall_method\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    539\u001B[39m \u001B[43m        \u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    540\u001B[39m \u001B[43m        \u001B[49m\u001B[43m*\u001B[49m\u001B[43mproxy_args_kwargs\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    541\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    542\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:2037\u001B[39m, in \u001B[36mwrap_fx_proxy\u001B[39m\u001B[34m(tx, proxy, example_value, subclass_type, **options)\u001B[39m\n\u001B[32m   2029\u001B[39m kwargs = {\n\u001B[32m   2030\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mtx\u001B[39m\u001B[33m\"\u001B[39m: tx,\n\u001B[32m   2031\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mproxy\u001B[39m\u001B[33m\"\u001B[39m: proxy,\n\u001B[32m   (...)\u001B[39m\u001B[32m   2034\u001B[39m     **options,\n\u001B[32m   2035\u001B[39m }\n\u001B[32m   2036\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m subclass_type \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m2037\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mwrap_fx_proxy_cls\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtarget_cls\u001B[49m\u001B[43m=\u001B[49m\u001B[43mTensorVariable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2038\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   2039\u001B[39m     result = wrap_fx_proxy_cls(target_cls=TensorWithTFOverrideVariable, **kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:2124\u001B[39m, in \u001B[36mwrap_fx_proxy_cls\u001B[39m\u001B[34m(target_cls, tx, proxy, example_value, subclass_type, **options)\u001B[39m\n\u001B[32m   2119\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m torch._dynamo.utils._disable_saved_tensors_hooks_during_tracing():\n\u001B[32m   2120\u001B[39m     \u001B[38;5;66;03m# with preserve_rng_state():\u001B[39;00m\n\u001B[32m   2121\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m example_value \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m   2122\u001B[39m         \u001B[38;5;66;03m# only allow_non_graph_fake in this instance because we handle the non-fake\u001B[39;00m\n\u001B[32m   2123\u001B[39m         \u001B[38;5;66;03m# cases properly below.\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m2124\u001B[39m         example_value = \u001B[43mget_fake_value\u001B[49m\u001B[43m(\u001B[49m\u001B[43mproxy\u001B[49m\u001B[43m.\u001B[49m\u001B[43mnode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mallow_non_graph_fake\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[32m   2126\u001B[39m     \u001B[38;5;66;03m# Handle recursive calls here\u001B[39;00m\n\u001B[32m   2127\u001B[39m     \u001B[38;5;28;01melif\u001B[39;00m maybe_get_fake_mode(example_value) \u001B[38;5;129;01mis\u001B[39;00m tx.fake_mode:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/_dynamo/utils.py:2082\u001B[39m, in \u001B[36mget_fake_value\u001B[39m\u001B[34m(node, tx, allow_non_graph_fake)\u001B[39m\n\u001B[32m   2079\u001B[39m     \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(cause, \u001B[38;5;167;01mTypeError\u001B[39;00m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33margument\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(cause):\n\u001B[32m   2080\u001B[39m         unimplemented(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mTypeError \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnode.target\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcause\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m-> \u001B[39m\u001B[32m2082\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m TorchRuntimeError(\u001B[38;5;28mstr\u001B[39m(e)).with_traceback(e.__traceback__) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   2084\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m allow_non_graph_fake:\n\u001B[32m   2085\u001B[39m     _ = pytree.tree_map_only(\n\u001B[32m   2086\u001B[39m         torch.Tensor, functools.partial(ensure_graph_fake, tx=tx), ret_val\n\u001B[32m   2087\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/_dynamo/utils.py:2017\u001B[39m, in \u001B[36mget_fake_value\u001B[39m\u001B[34m(node, tx, allow_non_graph_fake)\u001B[39m\n\u001B[32m   2015\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m   2016\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m tx.fake_mode, enable_python_dispatcher():\n\u001B[32m-> \u001B[39m\u001B[32m2017\u001B[39m         ret_val = \u001B[43mwrap_fake_exception\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   2018\u001B[39m \u001B[43m            \u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_node\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtx\u001B[49m\u001B[43m.\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnnmodule\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2019\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2020\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m Unsupported:\n\u001B[32m   2021\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/_dynamo/utils.py:1574\u001B[39m, in \u001B[36mwrap_fake_exception\u001B[39m\u001B[34m(fn)\u001B[39m\n\u001B[32m   1572\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mwrap_fake_exception\u001B[39m(fn):\n\u001B[32m   1573\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1574\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1575\u001B[39m     \u001B[38;5;28;01mexcept\u001B[39;00m UnsupportedFakeTensorException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m   1576\u001B[39m         \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mexc\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m unimplemented\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/_dynamo/utils.py:2018\u001B[39m, in \u001B[36mget_fake_value.<locals>.<lambda>\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m   2015\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m   2016\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m tx.fake_mode, enable_python_dispatcher():\n\u001B[32m   2017\u001B[39m         ret_val = wrap_fake_exception(\n\u001B[32m-> \u001B[39m\u001B[32m2018\u001B[39m             \u001B[38;5;28;01mlambda\u001B[39;00m: \u001B[43mrun_node\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtx\u001B[49m\u001B[43m.\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnnmodule\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2019\u001B[39m         )\n\u001B[32m   2020\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m Unsupported:\n\u001B[32m   2021\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/_dynamo/utils.py:2150\u001B[39m, in \u001B[36mrun_node\u001B[39m\u001B[34m(tracer, node, args, kwargs, nnmodule)\u001B[39m\n\u001B[32m   2148\u001B[39m         unimplemented(make_error_message(e), from_exc=e)\n\u001B[32m   2149\u001B[39m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m-> \u001B[39m\u001B[32m2150\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(make_error_message(e)).with_traceback(\n\u001B[32m   2151\u001B[39m             e.__traceback__\n\u001B[32m   2152\u001B[39m         ) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01me\u001B[39;00m\n\u001B[32m   2154\u001B[39m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(op)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/_dynamo/utils.py:2134\u001B[39m, in \u001B[36mrun_node\u001B[39m\u001B[34m(tracer, node, args, kwargs, nnmodule)\u001B[39m\n\u001B[32m   2132\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m node.target(*args, **kwargs)\n\u001B[32m   2133\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m op == \u001B[33m\"\u001B[39m\u001B[33mcall_method\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m-> \u001B[39m\u001B[32m2134\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnode\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2135\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m op == \u001B[33m\"\u001B[39m\u001B[33mcall_module\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m   2136\u001B[39m     \u001B[38;5;28;01massert\u001B[39;00m nnmodule \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/utils/_stats.py:21\u001B[39m, in \u001B[36mcount.<locals>.wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m     19\u001B[39m     simple_call_counter[fn.\u001B[34m__qualname__\u001B[39m] = \u001B[32m0\u001B[39m\n\u001B[32m     20\u001B[39m simple_call_counter[fn.\u001B[34m__qualname__\u001B[39m] = simple_call_counter[fn.\u001B[34m__qualname__\u001B[39m] + \u001B[32m1\u001B[39m\n\u001B[32m---> \u001B[39m\u001B[32m21\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1238\u001B[39m, in \u001B[36mFakeTensorMode.__torch_dispatch__\u001B[39m\u001B[34m(self, func, types, args, kwargs)\u001B[39m\n\u001B[32m   1234\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m (\n\u001B[32m   1235\u001B[39m     torch._C._get_dispatch_mode(torch._C._TorchDispatchModeKey.FAKE) \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1236\u001B[39m ), func\n\u001B[32m   1237\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1238\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdispatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtypes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1239\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[32m   1240\u001B[39m     log.exception(\u001B[33m\"\u001B[39m\u001B[33mfake tensor raised TypeError\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1692\u001B[39m, in \u001B[36mFakeTensorMode.dispatch\u001B[39m\u001B[34m(self, func, types, args, kwargs)\u001B[39m\n\u001B[32m   1689\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m func(*args, **kwargs)\n\u001B[32m   1691\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.cache_enabled:\n\u001B[32m-> \u001B[39m\u001B[32m1692\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_cached_dispatch_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtypes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1693\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1694\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._dispatch_impl(func, types, args, kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1339\u001B[39m, in \u001B[36mFakeTensorMode._cached_dispatch_impl\u001B[39m\u001B[34m(self, func, types, args, kwargs)\u001B[39m\n\u001B[32m   1337\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1338\u001B[39m     \u001B[38;5;28mself\u001B[39m._validate_cache_key(func, args, kwargs)\n\u001B[32m-> \u001B[39m\u001B[32m1339\u001B[39m     output = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_dispatch_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtypes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1340\u001B[39m     entry = \u001B[38;5;28mself\u001B[39m._make_cache_entry(state, key, func, args, kwargs, output)\n\u001B[32m   1341\u001B[39m     key.strip_shape_env()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:2013\u001B[39m, in \u001B[36mFakeTensorMode._dispatch_impl\u001B[39m\u001B[34m(self, func, types, args, kwargs)\u001B[39m\n\u001B[32m   2011\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m   2012\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m in_kernel_invocation_manager(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m-> \u001B[39m\u001B[32m2013\u001B[39m         r = \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2014\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m not_implemented_error:\n\u001B[32m   2015\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m maybe_run_unsafe_fallback(not_implemented_error)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/_ops.py:716\u001B[39m, in \u001B[36mOpOverload.__call__\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m    715\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, /, *args, **kwargs):\n\u001B[32m--> \u001B[39m\u001B[32m716\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_op\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/_refs/__init__.py:4591\u001B[39m, in \u001B[36mview\u001B[39m\u001B[34m(a, *shape)\u001B[39m\n\u001B[32m   4589\u001B[39m \u001B[38;5;129m@register_decomposition\u001B[39m(aten.view.default)\n\u001B[32m   4590\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mview\u001B[39m(a: TensorLikeType, *shape: ShapeType) -> TensorLikeType:\n\u001B[32m-> \u001B[39m\u001B[32m4591\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_reshape_view_helper\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43mshape\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mallow_copy\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/_refs/__init__.py:3659\u001B[39m, in \u001B[36m_reshape_view_helper\u001B[39m\u001B[34m(a, allow_copy, *shape)\u001B[39m\n\u001B[32m   3656\u001B[39m shape = utils.extract_shape_from_varargs(shape, validate=\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[32m   3657\u001B[39m \u001B[38;5;66;03m# Reshape may be given a shape with a -1 length\u001B[39;00m\n\u001B[32m   3658\u001B[39m \u001B[38;5;66;03m# This indicates that the dimension's length should be inferred\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m3659\u001B[39m shape = \u001B[43mutils\u001B[49m\u001B[43m.\u001B[49m\u001B[43minfer_size\u001B[49m\u001B[43m(\u001B[49m\u001B[43mshape\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43ma\u001B[49m\u001B[43m.\u001B[49m\u001B[43mnumel\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   3661\u001B[39m \u001B[38;5;66;03m# Special-cases tensors with no elements\u001B[39;00m\n\u001B[32m   3662\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m guard_size_oblivious(a.numel() == \u001B[32m0\u001B[39m):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/_prims_common/__init__.py:901\u001B[39m, in \u001B[36minfer_size\u001B[39m\u001B[34m(shape, numel)\u001B[39m\n\u001B[32m    899\u001B[39m         torch._check(\u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;28;01mlambda\u001B[39;00m: \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33minvalid shape dimension \u001B[39m\u001B[38;5;132;01m{\u001B[39;00md\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m    900\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m dim \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m901\u001B[39m     \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_check\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    902\u001B[39m \u001B[43m        \u001B[49m\u001B[43mnumel\u001B[49m\u001B[43m \u001B[49m\u001B[43m==\u001B[49m\u001B[43m \u001B[49m\u001B[43mnewsize\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    903\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[33;43mf\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mshape \u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mshape\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[33;43m'\u001B[39;49m\u001B[33;43m is invalid for input of size \u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mnumel\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    904\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    905\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    906\u001B[39m     \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mfx\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mexperimental\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01msymbolic_shapes\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m definitely_true\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/__init__.py:1564\u001B[39m, in \u001B[36m_check\u001B[39m\u001B[34m(cond, message)\u001B[39m\n\u001B[32m   1549\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_check\u001B[39m(cond, message=\u001B[38;5;28;01mNone\u001B[39;00m):  \u001B[38;5;66;03m# noqa: F811\u001B[39;00m\n\u001B[32m   1550\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33mr\u001B[39m\u001B[33;03m\"\"\"Throws error containing an optional message if the specified condition\u001B[39;00m\n\u001B[32m   1551\u001B[39m \u001B[33;03m    is False.\u001B[39;00m\n\u001B[32m   1552\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m   1562\u001B[39m \u001B[33;03m            message. Default: ``None``\u001B[39;00m\n\u001B[32m   1563\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1564\u001B[39m     \u001B[43m_check_with\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;167;43;01mRuntimeError\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcond\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmessage\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/conda/envs/torch-env/lib/python3.12/site-packages/torch/__init__.py:1546\u001B[39m, in \u001B[36m_check_with\u001B[39m\u001B[34m(error_type, cond, message)\u001B[39m\n\u001B[32m   1542\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33mmessage must be a callable\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m   1544\u001B[39m     message_evaluated = \u001B[38;5;28mstr\u001B[39m(message())\n\u001B[32m-> \u001B[39m\u001B[32m1546\u001B[39m \u001B[38;5;28;01mraise\u001B[39;00m error_type(message_evaluated)\n",
      "\u001B[31mTorchRuntimeError\u001B[39m: Failed running call_method view(*(FakeTensor(..., device='cuda:0', size=(1024, 128, 32), dtype=torch.bfloat16,\n           grad_fn=<ViewBackward0>), 1024, 128, 4, 32), **{}):\nshape '[1024, 128, 4, 32]' is invalid for input of size 4194304\n\nfrom user code:\n   File \"/workspace/PathFinder/models/GPT.py\", line 337, in forward\n    x, kv_cache_layer = block(x, kv_cache=kv_cache[layer_idx])                  # [batch_size, seq_len, d_embed]\n  File \"/workspace/PathFinder/models/GPT.py\", line 274, in forward\n    attn_out, new_kv_cache = self.attn(x, kv_cache=kv_cache)\n  File \"/workspace/PathFinder/models/GPT.py\", line 90, in forward\n    q = q.view(batch_size, seq_len, self.config.n_heads, self.config.d_head).transpose(1, 2)\n\nSet TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n\n\nYou can suppress this exception and fall back to eager by setting:\n    import torch._dynamo\n    torch._dynamo.config.suppress_errors = True\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Save the model",
   "id": "df43a98cae309849"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Save model locally\n",
    "if train_config.debug:\n",
    "    output_dir = os.path.join(PROJECT_ROOT, \"checkpoints\", train_config.model_name, train_config.run_name)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    try:\n",
    "        model.save_pretrained(\n",
    "            output_dir,\n",
    "            safe_serialization=True\n",
    "        )\n",
    "        print(\"Model saved successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving model: {e}\")\n",
    "    # Push to Hugging Face Hub\n",
    "    #model.push_to_hub(\n",
    "    #    repo_id=f\"PathFinderKR/{train_config.model_name}-{train_config.run_name}\",\n",
    "    #    private=True,\n",
    "    #    use_auth_token=os.environ.get(\"HUGGINGFACE_TOKEN\")\n",
    "    #)\n",
    "    #print(f\"Model pushed to Hugging Face Hub: PathFinderKR/{train_config.model_name}-{train_config.run_name}\")"
   ],
   "id": "a587e8a215674e2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# To load the model later, you can use:\n",
    "# model = GPT(model_config)\n",
    "# model = model.from_pretrained(output_dir).to(device)"
   ],
   "id": "f3cad31e5a514fc0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Inference",
   "id": "1ed82e9a71b4c9bd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "user_prompt = \"To be, or not to be, that is the question\"\n",
    "input_ids = char_tokenizer.encode(user_prompt).unsqueeze(0).to(device)\n",
    "output = model.generate(\n",
    "    input_ids,\n",
    "    use_cache=True,\n",
    "    max_new_tokens=generation_config.max_new_tokens,\n",
    "    temperature=generation_config.temperature,\n",
    "    top_k=generation_config.top_k,\n",
    "    tokenizer=char_tokenizer\n",
    ")\n",
    "response = char_tokenizer.decode(output[0].squeeze().cpu().numpy())"
   ],
   "id": "847724c2f13f7a7b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"=\" * 50)\n",
    "print(\"User prompt: \")\n",
    "print(user_prompt)\n",
    "print(\"-\" * 50)\n",
    "print(\" Model Response:\")\n",
    "print(response)"
   ],
   "id": "1ea28687151601ea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Speedometer",
   "id": "85c7993c75040a06"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "speedometer(\n",
    "    model=model,\n",
    "    input_ids=char_tokenizer.encode(\"a\").unsqueeze(0).to(device),\n",
    "    use_cache=True,\n",
    "    warmup_tokens=100,\n",
    "    timing_tokens=100,\n",
    "    num_runs=5\n",
    ")"
   ],
   "id": "b2ce78011b613db2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "speedometer(\n",
    "    model=model,\n",
    "    input_ids=char_tokenizer.encode(\"a\").unsqueeze(0).to(device),\n",
    "    use_cache=False,\n",
    "    warmup_tokens=100,\n",
    "    timing_tokens=100,\n",
    "    num_runs=5\n",
    ")"
   ],
   "id": "297cc7c8a09ae162",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
